{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jo's trial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Read data & basic text prerpocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import shutil as sh\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"/home/yingjie/Desktop/Machine_Learning/Assignment4/data/\"\n",
    "#path2 = \"/home/yingjie/Desktop/Machine_Learning/Assignment4/data_clean/\"\n",
    "\n",
    "path = \"/Users/Pan/Google Drive/Data Science/Machine Learning/ML_Assignment4/data/\"\n",
    "path2 = \"/Users/Pan/Google Drive/Data Science/Machine Learning/ML_Assignment4/data_clean/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(path,thefile):\n",
    "    # Replace all numbers with \"NUM\" special character\n",
    "    num_dec = re.compile(\"[\\d]+\\.[\\d]+\")\n",
    "    num_comma = re.compile(\"[\\d]+,[\\d]+\")\n",
    "    num_reg = re.compile(\"[\\d]+\")\n",
    "\n",
    "    # Detect non-English characters\n",
    "    non_eng = re.compile(\"[^a-zA-Z\\n ]\")\n",
    "    \n",
    "    #open file\n",
    "    file=open(os.path.join(path,thefile), \"r\", encoding=\"iso-8859-15\")\n",
    "    text = file.read().lower()\n",
    "    file.close()\n",
    "    \n",
    "    # Replace various forms of numbers with NUM character\n",
    "    text = num_dec.sub(\"NUM\", text)\n",
    "    text = num_comma.sub(\"NUM\", text)\n",
    "    text = num_reg.sub(\"NUM\", text)\n",
    "\n",
    "    # Replace all non-English characters with a space\n",
    "    text = non_eng.sub(\" \", text)\n",
    "\n",
    "    # Replace double spaces with a single space\n",
    "    text = text.replace(\"  \", \" \")\n",
    "    \n",
    "    # Split the file into reviews based on \\n\n",
    "    text = text.split(\"\\n\")\n",
    "    \n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=data_preprocess(path,\"train.txt\")\n",
    "valid=data_preprocess(path,\"valid.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we brought two different brand switches to test this srwNUM from linksys and wsrNUM from netgear netgear switch is over NUM and this one is under NUM both of them are all gigabit ports linksys has NUM gigabit ports and netgear has NUM gigabit ports however this srwNUM has more functions and features than the netgear NUM switches for example this switch supports lags for gang ports together in different lacp groups netgear switch does not this switch allowing setup stp on top the lags netgear does not this switch loaded with current firmware netgear switch comes with a two years old firmware this switch is really good bargain for its functions features and speed it is a shining star comparing to all those overpriced competitors the only problem we have is that this switch generates some kind of apple talk probing when we have switch setup to do stp on top of lags that probing caused problem to our routers and vpn servers so we had to turn the stp off ',\n",
       " 'what needs to be said really that hasn t already been said a million times this is one of the greatest albums of all time  and arguably dylan s best i say it is but everyone has their favorites and with an artist like dylan it s hard to pin down one album as his best either way  if you dont own this you should be ashamed take a hint from jack black in high fidelity  if you dont own it dont let anyone know as for the audiophile discussion that s been popping up  this sacd hybrid sounds spectacular and if you re one of those people that really like good sound it s worth a repurchase even if it is a bit pricey however if you truly want the best sound for this album  go with the NUM gram mono mix reissue from sundazed vinyl on a good turntable nothing digital can hold a candle to it but whatever your poison this is a timeless classic that only gets better every time you hear it six words of advice  buy it buy it buy it ']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Create vocabulary\n",
    "\n",
    "reference source:https://stackoverflow.com/questions/40661684/tensorflow-vocabularyprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.contrib import learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5430"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_document_length = max([len(x.split(\" \")) for x in train])\n",
    "max_document_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the vocabularyprocessor object, setting the max lengh of the documents.\n",
    "vocab_processor = learn.preprocessing.VocabularyProcessor(max_document_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train=train[0:5]\n",
    "## Transform the documents using the vocabulary.\n",
    "x = np.array(list(vocab_processor.fit_transform(small_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=vocab_processor.fit_transform(small_train)\n",
    "#np.set_printoptions(threshold=np.nan)\n",
    "np.set_printoptions(threshold=100)\n",
    "list(y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract word:id mapping from the object.\n",
    "vocab_dict = vocab_processor.vocabulary_._mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sort the vocabulary dictionary on the basis of values(id).\n",
    "## Both statements perform same task.\n",
    "#sorted_vocab = sorted(vocab_dict.items(), key=operator.itemgetter(1))\n",
    "sorted_vocab = sorted(vocab_dict.items(), key = lambda x : x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<UNK>', 'we', 'brought', 'two', 'different', 'brand', 'switches', 'to', 'test', 'this', 'srwNUM', 'from', 'linksys', 'and', 'wsrNUM', 'netgear', 'switch', 'is', 'over', 'NUM', 'one', 'under', 'both', 'of', 'them', 'are', 'all', 'gigabit', 'ports', 'has', 'however', 'more', 'functions', 'features', 'than', 'the', 'for', 'example', 'supports', 'lags', 'gang', 'together', 'in', 'lacp', 'groups', 'does', 'not', 'allowing', 'setup', 'stp', 'on', 'top', 'loaded', 'with', 'current', 'firmware', 'comes', 'a', 'years', 'old', 'really', 'good', 'bargain', 'its', 'speed', 'it', 'shining', 'star', 'comparing', 'those', 'overpriced', 'competitors', 'only', 'problem', 'have', 'that', 'generates', 'some', 'kind', 'apple', 'talk', 'probing', 'when', 'do', 'caused', 'our', 'routers', 'vpn', 'servers', 'so', 'had', 'turn', 'off', 'what', 'needs', 'be', 'said', 'hasn', 't', 'already', 'been', 'million', 'times', 'greatest', 'albums', 'time', 'arguably', 'dylan', 's', 'best', 'i', 'say', 'but', 'everyone', 'their', 'favorites', 'an', 'artist', 'like', 'hard', 'pin', 'down', 'album', 'as', 'his', 'either', 'way', 'if', 'you', 'dont', 'own', 'should', 'ashamed', 'take', 'hint', 'jack', 'black', 'high', 'fidelity', 'let', 'anyone', 'know', 'audiophile', 'discussion', 'popping', 'up', 'sacd', 'hybrid', 'sounds', 'spectacular', 're', 'people', 'sound', 'worth', 'repurchase', 'even', 'bit', 'pricey', 'truly', 'want', 'go', 'gram', 'mono', 'mix', 'reissue', 'sundazed', 'vinyl', 'turntable', 'nothing', 'digital', 'can', 'hold', 'candle', 'whatever', 'your', 'poison', 'timeless', 'classic', 'gets', 'better', 'every', 'hear', 'six', 'words', 'advice', 'buy', 'these', 'photo', 'corners', 'metallic', 'they', 'grey', 'gold', 'much', 'sheen', 'stay', 'put', 'ones', 'wet', 'believe', 'there', 'aren', 'any', 'reviews', 'yet', 'must', 'thrash', 'NU', 'Ms', 'almost', 'certainly', 'death', 'scream', 'bloody', 'gore', 'could', 'give', 'run', 'money', 'during', 'year', 'love', 'everything', 'about', 'disc', 'playing', 'tight', 'vox', 'cool', 'lyrics', 'actually', 'make', 'think', 'quite', 'cd', 'impossible', 'find', 'days', 'just', 'heard', 'great', 'news', 'brazil', 'marquee', 'records', 'signed', 'deal', 'legendary', 'canadian', 'thrashers', 'sacrifice', 'release', 'first', 'three', 'torment', 'fire', 'forward', 'termination', 'soldiers', 'misfortune', 'plus', 'live', 'complete', 'show', 'cds', 'will', 'double', 'special', 'editions', 'full', 'bonus', 'tracks', 'probably', 'released', 'dvd', 'set', 'distribution', 'u', 'japan', 'handled', 'by', 'khaosmaster', 'disk', 'heaven', 'respectively', 'metal', 'lives', 'trying', 'move', 'away', 'fake', 'sugars', 'bad', 'my', 'memory', 'stevia', 'mild', 'licorice', 'taste', 'bothers', 'me', 'm', 'hyper', 'sensitive', 'since', 'hate', 'others', 'would', 'fine', 'picked', 'light', 'agave', 'syrup', 'health', 'food', 'grocery', 'store', 'made', 'cup', 'tea', 'subtly', 'flavor', 'white', 'sugar', 'd', 'initial', 'thought', 'slightly', 'toward', 'honey', 'though', 'doesn', 'strong', 'softer', 'or', 'somehow', 'very', 'pleasant', 'tell', 'office', 'baker', 'well', 'bought', 'game', 'ago', 'was', 'missing', 'decided', 'again', 'kinda', 'captian', 'bird', 'pray', 'how', 'cloak', 'ship', 'transfer', 'power', 'repairs', 'primary', 'seconary', 'weapons', 'little', 'skill', 'getting', 'targeting', 'lined', 'ships', 'place', 'fast', 'older', 'may', 'problems', 'graphics', 'start', 'page', 'especially', 'trek', 'klingons', 'new', 'adding', 'fan', 'collection', 'get', 'second', 'which', 'interviews', 'featurettes', 'recorded', 'no', 'video', 'interview', 'stanley', 'kubrick', 'also', 'extremely', 'interesting', 'particularly', 'film', 'buff', 'end', 'speaks', 'glowingly', 'arthur', 'clarke', 'refreshing', 'considering', 'at', 'he', 'keeping', 'financial', 'tether', 'intriguing', 'because', 'sporadic', 'commentary', 'provided', 'lockwood', 'dullea', 'consider', 'grave', 'mistake', 'included', 'additional', 'involved', 'production', 'am', 'grateful', 'course', 'many', 'gary', 'comments', 'pertinent', 'left', 'flail', 'misremember', 'information', 'were', 'fully', 'prepared', 'conjure', 'reference', 'feel', 've', 'gotten', 'performers', 'itself', 'enjoyable', 'haven', 'inquiries', 'strikes', 'reprehensible', 'worthy', 'sort', 'explanation', 'track', 'include', 'material', 'c', 'daniel', 'richter', 'moonwatcher', 'effects', 'wizard', 'douglas', 'trumbull', 'frederick', 'ordway', 'who', 'served', 'technical', 'science', 'consultant', 'gentlemen', 'still', 'us', 'doubt', 'glad', 'fortunately', 'meet', 'wonderful', 'expertise', 'treated', 'while', 'watching', 'commenting', 'dawn', 'man', 'sequence', 'instead', 'neither', 'whom', 'directly', 'service', 'length', 'noted', 'critics', 'historians', 'entire', 'notable', 'sequences', 'into', 'historical', 'perspective', 'cinematic', 'viewpoint', 'roger', 'ebert', 'provide', 'thoughts', 'strike', 'brief', 'cursory', 'going', 'awhile', 'repeat', 'shows', 'moon', 'too', 'dark', 'visible', 'theater', 'clear', 'image', 'general', 'looks', 'terrific', 'includes', 'colors', 'seen', 'glaringly', 'missed', 'opportunities', 'represents', 'remains', 'done', 'dare', 'hope', 'improved', 'criterion', 'someday', 'freely', 'admit', 'huge', 'after', 'few', 'episodes', 'seemed', 'promise', 'action', 'enough', 'human', 'feeling', 'lead', 'character', 'another', 'cartoon', 'cutout', 'adaption', 'now', 'episode', 'seven', 'completely', 'whole', 'series', 'started', 'packed', 'vigilante', 'against', 'men', 'crime', 'idea', 'promising', 'vicarious', 'entertainment', 'watch', 'hero', 'out', 'baddies', 'highly', 'imaginative', 'ways', 'progressively', 'degenerates', 'lengthy', 'soap', 'ridden', 'clich', 'eacute', 'scenes', 'feminine', 'talkfests', 'caring', 'female', 'relationships', 'issues', 'support', 'other', 'assorted', 'warm', 'fuzzy', 'aspects', 'such', 'emotional', 'acting', 'overwhelms', 'original', 'concept', 'literally', 'sections', 'bold', 'beautiful', 'spliced', 'oh', 'serious', 'method', 'where', 'exchange', 'deep', 'meaningfuls', 'near', 'whispers', 'grim', 'faces', 'worse', 'exactly', 'writers', 'did', 'dexter', 'damn', 'plot', 'line', 'baby', 'family', 'viewers', 'wanted', 'see', 'carve', 'change', 'dirty', 'diapers', 'daddy', 'fied', 'then', 'resort', 'unbelievably', 'contrived', 'writing', 'try', 'wrest', 'back', 'excitement', 'fans', 'fell', 'imagine', 'fluffy', 'girly', 'themes', 'being', 'introduced', 'arrow', 'attempt', 'attract', 'genre', 'totally', 'ruined', 'promised', 'pretty', 'park', 'brain', 'neutral', 'enjoy', 'moving', 'bogged', 'baggage', 'far', 'earnest', 'characters', 'competing', 'attention', 'emote', 'breathily', 'close', 'stuck', 'thick', 'infrequent', 'emerging', 'suds', 'fading', 'rapidly', 'excellent', 'examination', 'consumer', 'culture', 'corporate', 'america', 'tried', 'understand', 'co', 'opt', 'youth', 'advertising', 'frank', 'bottom', 'always', 'entertaining', 'look', 'madison', 'avenue', 'through', 'sixties', 'examinations', 'various', 'ad', 'campaigns', 'volvo', 'insisted', 'ads', 'cars', 'ugly', 'least', 'filled', 'defects', 'used', 'insightful', 'researched', 'fact', 'book', 'necessary', 'primer', 'doing', 'research', 'helped', 'become', 'text', 'refer', 'often', 'mainly', 'interest', 'supporting', 'cast', 'mehldau', 'redman', 'grenadier', 'ballard', 'never', 'kr', 'before', 'thoroughly', 'impressed', 'amazing', 'chops', 'penchant', 'quirky', 'haunting', 'melody', 'lines', 'miles', 'trumpet', 'song', 'selection', 'skip', 'songs', 'wait', 'deeper', 'slow', 'poignant', 'swinging', 'afro', 'sassy', 'boring', 'jazz', 'stuff', 'highlights', 'th', 'cross', 'final', 'nice', 'ps', 'ali', 'jackson', 'mutha', 'worst', 'ever', 'read', 'written', 'jerry', 'seinfeld', 'forwarded', 'him', 'seinfelds', 'name', 'lacks', 'humor', 'level', 'larry', 'davids', 'costanzas', 'chapters', 'repetetive', 'crappy', 'letters', 'stories', 'humorous', 'humour', 'lacking', 'giving', 'lowest', 'avoid', 'waste', 'broth', 'next', 'publication', 'loyal', 'friend', 'guess', 'without', 'reading', 'ok', 'kirby', 'thing', 'cute', 'pink', 'inhales', 'enemies', 'part', 'swallow', 'amazingly', 'fun', 'mario', 'dreamlike', 'worlds', 'continue', 'raving', 'here', 'books', 'harry', 'bosch', 'plots', 'easy', 'follow', 'dialogue', 'disappointed', 'blankets', 'liked', 'carter', 'item', 'received', 'sets', 'shower', 'months', 'daughter', 'born', 'found', 'thin', 'small', 'hooded', 'towels', 'larger', 'thicker', 'fabric', 'patterns', 'soft', 'warmth', 'durability', 'thickness', 'perhaps', 'appreciate', 'warmer', 'hoping', 'girl', 'grows', 'toddler', 'she', 'play', 'glue', 'works', 'nearly', 'including', 'plastic', 'wood', 'china', 'etc', 'directions', 'tube', 'patient', 'won', 'dry', 'immediately', 'superglue', 'running', 'household', 'recommended', 'sad', 'cancelled', 'sadder', 'couple', 'main', 'killed', 'movie', 'extras', 'finish', 'short', 'lived', 'agree', 'previous', 'reviewer', 'reminded', 'tone', 'atmosphere', 'atwood', 'handmaid', 'tale', 'novelif', 'enjoyed', 'nlmg', 'recommend', 'ht', 'ishiguro', 'prior', 'orphans', 'remarkable', 'items', 'consistent', 'voice', 'throughout', 'narrated', 'kathy', 'form', 'describe', 'indirect', 'plodding', 'addressing', 'negative', 'space', 'surounding', 'habitat', 'reader', 'peeling', 'onion', 'based', 'clues', 'ethical', 'raised', 'became', 'apparent', 'charatcers', 'clones', 'clone', 'implied', 'exactness', 'perfection', 'outcome', 'knew', 'result', 'flawed', 'sense', 'tommy', 'behaviorial', 'outbursts', 'lower', 'iq', 'inability', 'produce', 'meaningful', 'art', 'fit', 'purposes', 'program', 'ruth', 'easily', 'influenced', 'person', 'object', 'encountered', 'incoporated', 'images', 'magazines', 'hearsay', 'reality', 'ideas', 'although', 'demonstrate', 'lot', 'empathy', 'completing', 'most', 'rounded', 'story', 'her', 'conformist', 'hailsham', 'cottages', 'system', 'consumed', 'sex', 'per', 'se', 'lack', 'meaning', 'beyond', 'mere', 'intense', 'desire', 'souls', 'limitations', 'development', 'seem', 'able', 'overcome', 'due', 'methodology', 'treatment', 'origins', 'solid', 'intrigue', 'mature', 'absurd', 'nonsensical', 'ending', 'outlines', 'experience', 'jo', 'goodman', 'season', 'sinful', 'interconnected', 'threads', 'stunted', 'choked', 'protracted', 'sherry', 'actions', 'wants', 'ensure', 'villain', 'silence', 'force', 'exile', 'feels', 'anger', 'physically', 'emotionally', 'abused', 'woman', 'loves', 'huh', 'woodridge', 'denigrates', 'lily', 'right', 'front', 'himself', 'letting', 'terrorized', 'young', 'women', 'walk', 'ineptly', 'stretches', 'allows', 'chance', 'return', 'terrorize', 'believable', 'finale', 'maneuvers', 'contrive', 'dumb', 'contains', 'banter', 'witty', 'suspenseful', 'unfortunately', 'heroine', 'desperately', 'lacked', 'chemistry', 'interaction', 'between', 'pair', 'weird', 'forget', 'equal', 'ground', 'appeared', 'went', 'dominant', 'persona', 'herself', 'didn', 'romance', 'empowering', 'jostling', 'come', 'poor', 'honors', 'respects', 'goes', 'wishes', 'obscenely', 'violent', 'demands', 'voices', 'early', 'mouths', 'heartfelt', 'affection', 'grinds', 'dust', 'meeting', 'relationship', 'street', 'definitely', 'around', 'supposed', 'trust', 'each', 'married', 'dwarfed', 'seems', 'having', 'debased', 'aggressive', 'sensually', 'melt', 'touch', 'typical', 'novels', 'aggression', 'belongs', 'scoundrels', 'orphaned', 'entrusted', 'takes', 'responsibility', 'cheers', 'sidelines', 'trivial', 'purpose', 'novel', 'stages', 'scene', 'towards', 'children', 'dangerous', 'roles', 'timidly', 'steps', 'aside', 'pummels', 'scratches', 'cripples', 'returns', 'later', 'key', 'stripping', 'granville', 'foresight', 'recognize', 'lets', 'alive', 'clueless', 'thereof', 'indicate', 'void', 'intelligence', 'normal', 'wouldn', 'less', 'attempts', 'wring', 'confession', 'thinking', 'bear', 'night', 'terrorizes', 'once', 'thrusts', 'stiletto', 'maimed', 'incapacitated', 'laughs', 'basically', 'talks', 'knowing', 'shrugs', 'disparaging', 'remark', 'aimed', 'despite', 'potential', 'secures', 'oath', 'endangers', 'anyway', 'bright', 'needless', 'horribly', 'makes', 'inept', 'shine', 'Mth', 'century', 'cheer', 'leading', 'squad', 'sixteen', 'miss', 'lilith', 'sterling', 'fosters', 'l', 'abbaye', 'de', 'sacre', 'coeur', 'convent', 'france', 'parents', 'died', 'insidious', 'wycliff', 'standish', 'baron', 'visits', 'abbey', 'seeking', 'governess', 'intents', 'extend', 'duties', 'realm', 'servicing', 'friends', 'carnal', 'pleasures', 'mentor', 'sister', 'mary', 'joseph', 'arranges', 'escape', 'london', 'snatch', 'five', 'twenty', 'covent', 'garden', 'common', 'thief', 'saving', 'life', 'viscount', 'sheridan', 'alexander', 'grantham', 'dressed', 'boy', 'auburn', 'hair', 'dyed', 'shiv', 'side', 'react', 'boys', 'haul', 'escapes', 'unscathed', 'condition', 'deteriorates', 'affectionately', 'referred', 'home', 'succor', 'spares', 'expense', 'enlisting', 'physician', 'aid', 'bring', 'cares', 'vigil', 'bedside', 'nights', 'process', 'care', 'leave', 'subplots', 'pinch', 'dash', 'midge', 'overshadowed', 'except', 'spend', 'discovers', 'incident', 'saves', 'glimpses', 'tortured', 'past', 'reacts', 'violently', 'seemingly', 'innocuous', 'things', 'prompt', 'throwing', 'taking', 'begins', 'permission', 'whisks', 'seat', 'teach', 'proper', 'anything', 'agrees', 'allowed', 'whenever', 'questions', 'asked', 'rendezvous', 'intimately', 'reveals', 'happened', 'leaving', 'realize', 'reservations', 'took', 'long', 'regales', 'affections', 'coincidence', 'clandestine', 'confederacy', 'english', 'crown', 'parentage', 'wounded', 'soul', 'secret', 'history', 'nopolean', 'godmother', 'lady', 'georgia', 'pendelton', 'countess', 'rivendale', 'head', 'wasn', 'delivering', 'mentioned', 'showed', 'highlighted', 'apathy', 'harm', 'inflicted', 'upon', 'veritable', 'ruse', 'concocted', 'parts', 'negligence', 'provincial', 'mind', 'sanctions', 'ah', 'characterizations', 'piece', 'clamp', 'surely', 'handy', 'situations', 'heavy', 'duty', 'capable', 'sturdy', 'gadget', 'freak', 'emergency', 'networking', 'chapter', 'winsock', 'code', 'helpful']\n"
     ]
    }
   ],
   "source": [
    "## Treat the id's as index into list and create a list of words in the ascending order of id's\n",
    "## word with id i goes at index i of the list.\n",
    "vocabulary = list(list(zip(*sorted_vocab))[0])\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hi How are you? i am fine and you\"\n",
    "token=nltk.word_tokenize(text)\n",
    "bigrams=ngrams(token,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source:https://stackoverflow.com/questions/24347029/python-nltk-bigrams-trigrams-fourgrams\n",
    "def words_to_ngrams(words, n, sep=\",\"):\n",
    "    return [sep.join(words[i:i+n]) for i in range(len(words)-n+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def docs_to_ngrams(docs,n,sep=\",\"):\n",
    "    for i in range(len(docs)):\n",
    "        docs[i]=words_to_ngrams(docs[i],n)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, numpy.int64 found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-9870b39bbbd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdocs_to_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-64-0e96408bc6b7>\u001b[0m in \u001b[0;36mdocs_to_ngrams\u001b[0;34m(docs, n, sep)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdocs_to_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mdocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwords_to_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-dad6e5b203fb>\u001b[0m in \u001b[0;36mwords_to_ngrams\u001b[0;34m(words, n, sep)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwords_to_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-57-dad6e5b203fb>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwords_to_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, numpy.int64 found"
     ]
    }
   ],
   "source": [
    "docs_to_ngrams(x,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5430"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "964"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x[0])):\n",
    "        docs[i]=words_to_ngrams(docs[i],n)\n",
    "    return docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
